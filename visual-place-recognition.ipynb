{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_addons as tfa\nimport os\nimport random\nimport numpy as np\nfrom tensorflow.keras.applications.vgg16 import VGG16 \nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the random seed for reproducibility\nrandom.seed(42)\nnp.random.seed(42)\ntf.random.set_seed(42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 1: Dataset Preparation\ndataset_path = \"/kaggle/input/d/adriankucharski12345/nordland-train/Nordland_Train\"  # Replace with the actual path to the Nordland dataset\nseasons = [\"summer\", \"spring\", \"winter\", \"fall\"]\nimage_size = (224, 224)  # Resize images to this size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 2: Data Preprocessing\ndef preprocess_image(image_path):\n    img = load_img(image_path, target_size=image_size)\n    img = img_to_array(img)\n    img = img / 255.0  # Normalize pixel values to the range [0, 1]\n    return img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to generate anchor, positive, negative triplets\ndef generate_triplets(dataset_path):\n    seasons = [\"summer\", \"spring\", \"winter\", \"fall\"]\n    triplets = []\n\n    # Loop over the seasons\n    for season in seasons:\n        season_dir = os.path.join(dataset_path, season)\n        images = os.listdir(season_dir)\n\n        # Generate anchor, positive, negative triplets for each image\n        for i in range(len(images)):\n            anchor_image = os.path.join(season_dir, images[i])\n            positive_season = random.choice(seasons)\n            while positive_season == season:\n                positive_season = random.choice(seasons)\n            positive_dir = os.path.join(dataset_path, positive_season)\n            positive_image = os.path.join(positive_dir, images[i])\n\n            # Randomly select a negative image from a different season\n            negative_season = random.choice(seasons)\n            while negative_season == season:\n                negative_season = random.choice(seasons)\n            negative_dir = os.path.join(dataset_path, negative_season)\n            negative_images = os.listdir(negative_dir)\n            negative_image = os.path.join(negative_dir, random.choice(negative_images))\n\n            triplets.append((anchor_image, positive_image, negative_image, season, positive_season, negative_season))\n\n    return triplets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"triplets = generate_triplets(dataset_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 4: Triplet Network Architecture\nbase_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\nflatten = tf.keras.layers.Flatten()(base_model.output)\nembeddings = tf.keras.layers.Dense(256)(flatten)\ntriplet_model = tf.keras.Model(inputs=base_model.input, outputs=embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the optimizer\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n\n# Define the Online Triplet Loss\ndef triplet_loss(anchor_embeddings, positive_embeddings, negative_embeddings, margin=0.1):\n    anchor_positive_dist = tf.reduce_sum(tf.square(anchor_embeddings - positive_embeddings), axis=1)\n    anchor_negative_dist = tf.reduce_sum(tf.square(anchor_embeddings - negative_embeddings), axis=1)\n    loss = tf.maximum(anchor_positive_dist - anchor_negative_dist + margin, 0.0)\n    loss = tf.reduce_mean(loss)\n    return loss\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\n\nbatch_size = 64\nepochs = 5\n\nnum_batches = len(triplets) // batch_size\n\nfor epoch in range(epochs):\n    np.random.shuffle(triplets)\n    \n    epoch_loss = 0.0\n    \n    with tqdm(total=num_batches, desc=f\"Epoch {epoch+1}/{epochs}\", unit=\"batch\") as pbar:\n        for batch in range(num_batches):\n            anchor_batch = []\n            positive_batch = []\n            negative_batch = []\n\n            batch_triplets = triplets[batch*batch_size:(batch+1)*batch_size]\n\n            for triplet in batch_triplets:\n                anchor_image = triplet[0]\n                positive_image = triplet[1]\n                negative_image = triplet[2]\n\n                # Preprocess and append images to the respective batches\n                anchor_img = preprocess_image(anchor_image)\n                positive_img = preprocess_image(positive_image)\n                negative_img = preprocess_image(negative_image)\n\n                anchor_batch.append(anchor_img)\n                positive_batch.append(positive_img)\n                negative_batch.append(negative_img)\n\n            anchor_batch = np.array(anchor_batch)\n            positive_batch = np.array(positive_batch)\n            negative_batch = np.array(negative_batch)\n\n            with tf.GradientTape() as tape:\n                anchor_embeddings = triplet_model(anchor_batch, training=True)\n                positive_embeddings = triplet_model(positive_batch, training=True)\n                negative_embeddings = triplet_model(negative_batch, training=True)\n\n                # Generate dummy labels indicating valid triplets\n                #labels = np.ones((batch_size, 1))\n\n                loss_value = triplet_loss(anchor_embeddings, positive_embeddings, negative_embeddings)\n\n            grads = tape.gradient(loss_value, triplet_model.trainable_variables)\n            optimizer.apply_gradients(zip(grads, triplet_model.trainable_variables))\n\n            epoch_loss += loss_value.numpy()\n            \n            pbar.set_postfix({\"Loss\": epoch_loss / (batch + 1)})\n            pbar.update(1)\n    \n    epoch_loss /= num_batches\n    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss}\")","metadata":{"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset_path = \"/kaggle/input/d/adriankucharski12345/nordland-test/Nordland_Test\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_distance(feature_vector1, feature_vector2):\n    # Calculate the Euclidean distance between the two feature vectors\n    distance = np.linalg.norm(feature_vector1 - feature_vector2)\n    return distance","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seasons = [\"summer\", \"spring\", \"winter\", \"fall\"]\n\n# Create lists to store the feature vectors for each season\nfeature_vectors = {season: [] for season in seasons}\n\n# Process the test images and extract features\nfor season in seasons:\n    season_path = os.path.join(test_dataset_path, season)\n    image_files = sorted(os.listdir(season_path))\n    \n    for image_file in image_files:\n        image_path = os.path.join(season_path, image_file)\n        \n        # Preprocess the image (e.g., resize, normalize)\n        preprocessed_image = preprocess_image(image_path)\n        \n        # Obtain the feature vector using the trained model\n        feature_vector = triplet_model.predict(np.expand_dims(preprocessed_image, axis=0), verbose=0)\n\n        \n        # Store the feature vector for the corresponding season\n        feature_vectors[season].append(feature_vector)\n\n# Perform place recognition for each query season against reference seasons\nfor query_season in seasons:\n    correct_matches = 0\n    total_evaluated_places = 0\n    \n    for query_feature in feature_vectors[query_season]:\n        closest_distance = float('inf')\n        closest_place = None\n        \n        # Compare the query feature vector with reference feature vectors from other seasons\n        for ref_season in seasons:\n            if ref_season != query_season:\n                for ref_feature in feature_vectors[ref_season]:\n                    # Calculate the distance between query and reference feature vectors\n                    distance = calculate_distance(query_feature, ref_feature)\n\n                    \n                    if distance < closest_distance:\n                        closest_distance = distance\n                        closest_place = ref_season\n        \n        # Check if the closest place is within a 5-frame window\n        if abs(seasons.index(query_season) - seasons.index(closest_place)) <= 1:\n            correct_matches += 1\n        \n        total_evaluated_places += 1\n    \n    # Calculate the fraction of correct matches\n    fc = correct_matches / total_evaluated_places\n\n    \n    print(f\"Query Season: {query_season}, Fraction of Correct Matches: {fc}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"triplet_model.save(\"/kaggle/working/triplet_model.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_place_recognition(triplet_model, dataset_path, seasons):\n    def extract_features(image_path):\n        img = preprocess_image(image_path)\n        features = triplet_model.predict(np.expand_dims(img, axis=0), verbose=0)\n        return features\n\n    for reference_season in seasons:\n        reference_dir = os.path.join(dataset_path, reference_season)\n        for query_season in seasons:\n            query_dir = os.path.join(dataset_path, query_season)\n            num_correct_matches = 0\n            num_evaluated_places = 0\n            for query_image in os.listdir(query_dir):\n                query_image_path = os.path.join(query_dir, query_image)\n                query_features = extract_features(query_image_path)\n\n                closest_distance = float('inf')\n                closest_place = None\n\n                for reference_image in os.listdir(reference_dir):\n                    reference_image_path = os.path.join(reference_dir, reference_image)\n                    reference_features = extract_features(reference_image_path)\n\n                    distance = np.linalg.norm(query_features - reference_features)\n\n                    if distance < closest_distance:\n                        closest_distance = distance\n                        closest_place = reference_image\n\n                query_index = int(query_image.split('.')[0])\n                closest_index = int(closest_place.split('.')[0])\n\n                if abs(query_index - closest_index) <= 5:\n                    num_correct_matches += 1\n\n                num_evaluated_places += 1\n\n            fraction_correct_matches = num_correct_matches / num_evaluated_places\n\n    print(f\"For seasons: {reference_season} vs {query_season}\")\n    print(f\"Fraction of correct matches: {fraction_correct_matches}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Usage\nevaluate_place_recognition(triplet_model, test_dataset_path, seasons)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}